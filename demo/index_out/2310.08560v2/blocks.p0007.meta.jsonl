{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0001", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0001", "type": "text", "text": "# MemGPT: Towards LLMs as Operating Systems", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0002", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0002", "type": "text", "text": "## Figure 7. Nested KV retrieval task performance.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0003", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0003", "type": "text", "text": "MemGPT is the only approach that is able to consistently complete the nested KV task beyond 2 nesting levels. While GPT-4 Turbo performs better as a baseline, MemGPT with GPT-4 Turbo performs worse than MemGPT with GPT-4.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0004", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0004", "type": "text", "text": "![Figure 7: Nested KV retrieval task performance](https://i.imgur.com/placeholder.png)", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0005", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0005", "type": "text", "text": "*Accuracy vs. Nesting Level for different models:*\n- **GPT-3.5**: Dashed blue line with triangle markers\n- **GPT-4 Turbo**: Dashed green line with square markers\n- **MemGPT (GPT-4 Turbo)**: Dotted red line with square markers\n- **GPT-4**: Solid blue line with circle markers\n- **MemGPT (GPT-3.5)**: Dashed orange line with triangle markers\n- **MemGPT (GPT-4)**: Solid red line with circle markers", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0006", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0006", "type": "text", "text": "---", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0007", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0007", "type": "text", "text": "## Figure 8. An example of MemGPT (left) solving the nested KV task (UUIDs shortened for readability).", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0008", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0008", "type": "text", "text": "In this particular example, the key-value pair has two nesting levels: `831..ea5 → 5b8..4c3 → f37..617`. The MemGPT agent returns the final answer when a query for the final value (`f37..617`) only returns one result, indicating that it is not also a key.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0009", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0009", "type": "text", "text": "![Figure 8: Example of MemGPT solving nested KV task](https://i.imgur.com/placeholder.png)", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0010", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0010", "type": "text", "text": "---", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0011", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0011", "type": "text", "text": "### Text from the document:", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0012", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0012", "type": "text", "text": "Izacard et al., 2021), and sampled a subset of 50 questions for evaluation. Both the sampled questions and embedded Wikipedia passages are publicly released. We evaluate the performance of both MemGPT and baselines with an LLM-judge, to ensure that the answer is properly derived from the retrieved documents and to avoid non-exact string matches being considered incorrect.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0013", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0013", "type": "text", "text": "We show the results for the document QA task in Figure 5. The fixed-context baselines performance is capped roughly at the performance of the retriever, as they use the information that is presented in their context window (e.g. if the embedding search retriever fails to surface the gold article using the provided question, the fixed-context baselines are guaranteed to never see the gold article). By contrast, MemGPT is effectively able to make multiple calls to the retriever by querying archival storage, allowing it to scale to larger effective context lengths. MemGPT actively retrieves documents from its archival storage (and can iteratively page through results), so the total number of documents available to MemGPT is no longer limited by the number of documents that fit within the LLM processor’s context window.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0014", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0014", "type": "text", "text": "The document QA task is challenging for all methods due to the limitations of embedding-based similarity search. We observe that the golden document for chosen question (as annotated by NaturalQuestions-Open) often appears outside of the first dozen retrieved results, if not even further. The retriever performance translates directly to the fixed-context baseline results: GPT-4’s accuracy is relatively low with few retrieved documents, and continues to improve as additional documents are added to the context window, as it correctly limits itself to answering questions based on information in retrieved documents. While MemGPT is theoretically not limited by sub-optimal retriever performance (even if the embedding-based ranking is noisy, as long as the full retriever ranking contains the gold document it can still be found with enough retriever calls via pagination), we observe that MemGPT will often stop paging through retriever results before exhausting the retriever database.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0015", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0015", "type": "text", "text": "To evaluate the fixed-context baselines against MemGPT past their default context lengths, we truncate the document segments returned by the retriever to fix the same number of documents into the available context. As expected, document truncation reduces accuracy as documents shrink as the chance of the relevant snippet (in the gold document) being omitted grows, as shown in Figure 5. MemGPT has significantly degraded performance using GPT-3.5, due to its limited function calling capabilities, and performs best using GPT-4.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0016", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0016", "type": "text", "text": "### 3.2.2. NESTED KEY-VALUE RETRIEVAL (KV)", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:b0017", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "block_id": "p7:b0017", "type": "text", "text": "We introduce a new task based on the synthetic Key-Value retrieval proposed in prior work (Liu et al., 2023a). The goal of this task is to demonstrate how MemGPT can collate information from multiple data sources. In the original KV task, the authors generated a synthetic dataset of key-value pairs, where each key and value is a 128-bit UUID (universally unique identifier). The agent is then given a key, and asked to return the associated value for the key. We create a version of the KV task, *nested KV retrieval*,", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
