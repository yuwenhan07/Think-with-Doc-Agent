{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p1:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 1, "text": "- The paper introduces **MemGPT**, an OS-inspired system for large language models (LLMs) that enables extended context handling by treating the LLM’s context window as a constrained memory resource, analogous to physical memory in traditional operating systems.\n- It proposes **virtual context management**, a technique inspired by virtual memory paging, which allows LLMs to “page” information in and out between their limited context window (main memory) and external storage (disk), thereby creating the illusion of infinite context.\n- The approach leverages recent advances in LLM function calling to enable agents to read/write external data, modify their context, and control response timing, allowing iterative refinement of context for better task performance.\n- MemGPT is evaluated in two domains: **document analysis** (handling documents larger than the LLM’s context window) and **multi-session chat** (creating conversational agents that remember, reflect, and evolve over time).\n- The authors argue that directly scaling context length is computationally expensive and often ineffective, making alternative techniques like virtual context management critical for practical long-context applications.\n- The paper releases code and data at [https://research.memgpt.ai](https://research.memgpt.ai) and is authored by researchers from the University of California, Berkeley."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p2:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 2, "text": "- **Page 2 introduces MemGPT**, an OS-inspired memory architecture for LLMs that mimics virtual memory by managing in-context and out-of-context data, enabling longer effective context windows through external storage and memory management functions.\n\n- **Figure 1** demonstrates MemGPT responding to a system alert (\"Memory Pressure\") by writing key facts (\"Birthday is February 7\", \"Boyfriend named James\") to persistent memory, illustrating proactive memory management.\n\n- **Figure 2** shows MemGPT retrieving out-of-context data via a `recall_storage.search(\"six flags\")` function call, bringing relevant historical information (e.g., past visits, meeting James there) into the current context to enrich the conversation.\n\n- **Section 2.1 (Main context)** defines the prompt tokens as three parts: **system instructions** (static, control flow), **working context** (read/write, for key user/persona facts), and **FIFO Queue** (rolling message history with a recursive summary at index 0).\n\n- **Section 2.2 (Queue Manager)** explains that it manages the FIFO queue and recall storage, appending new messages and LLM outputs to recall storage, and retrieving messages from recall storage when called, appending them to the queue for context.\n\n- The page emphasizes that MemGPT overcomes finite context limitations in LLMs for domains like document analysis and conversational agents by enabling context-aware, long-term memory and persona consistency through its memory hierarchy."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p3:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 3, "text": "**Summary of Page 3 (MemGPT: Towards LLMs as Operating Systems):**\n\n- **Figure 3** illustrates MemGPT’s architecture, where a fixed-context LLM is augmented with a hierarchical memory system (system instructions, working context, FIFO queue, archival storage, recall storage) and function-based memory management. The LLM’s prompt tokens (main context) feed into the model, while completion tokens are parsed as function calls by the Function Executor.\n\n- The **queue manager** controls context overflow via a two-tier eviction policy: a “memory pressure” warning at 70% context usage prompts the LLM to store data in working context or archival storage; at 100% usage, it flushes the queue by evicting messages (e.g., 50% of context), generating a recursive summary, and storing evicted content in recall storage for later retrieval.\n\n- The **function executor** handles completion tokens by interpreting them as function calls to move data between main and external contexts. Memory edits and retrievals are self-directed, guided by system instructions that include a memory hierarchy description and a function schema with natural language descriptions.\n\n- During inference, the LLM processes the main context, generates an output string, which is parsed and validated by MemGPT. Valid functions are executed, and results (including errors) are fed back to the LLM, creating a feedback loop for adaptive behavior.\n\n- MemGPT proactively manages token limits by issuing warnings and using pagination in retrieval to prevent context overflow, ensuring the system remains within its finite context window while enabling long-term memory access.\n\n- The system enables multi-step retrieval through function chaining, triggered by the LLM generating `request_heartbeat=true` in its output, allowing it to perform complex, iterative tasks."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p4:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 4, "text": "- **Table 1** compares context lengths of major LLMs and APIs (as of Jan 2024), showing context window sizes in tokens and approximate message counts, with open-source models (e.g., Llama, Mistral, Yi-34B-200k) and proprietary models (e.g., GPT-4, Claude 2) listed.\n- **Figure 4** illustrates MemGPT’s ability to update stored information in real-time during a conversation, demonstrating how it modifies its working context memory (e.g., changing “Boyfriend named James” to “Ex-boyfriend named James”) based on user input.\n- Section **2.4** describes MemGPT’s control flow and function chaining: events (user messages, system alerts, timed triggers) are parsed into plain text and fed to the LLM; function calls can be synchronous (immediate return) or asynchronous (yield, waiting for next event).\n- Section **3 (Experiments)** outlines evaluations in two domains: conversational agents (using an expanded Multi-Session Chat dataset) and document analysis (including a new nested key-value retrieval task for multi-hop retrieval), with datasets and code publicly released at https://research.memgpt.ai.\n- **Implementation details** clarify the specific OpenAI model endpoints used (e.g., GPT-4 Turbo = gpt-4-1106-preview, 128k context) and note that experiments use GPT-4, GPT-4 Turbo, and GPT-3.5 to assess model impact.\n- Section **3.1** defines the two key criteria for conversational agents: **Consistency** (maintaining coherent, aligned dialogue) and **Engagement** (personalizing interactions using long-term user knowledge)."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p5:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 5, "text": "- The page presents two key evaluation tasks for MemGPT: Deep Memory Retrieval (DMR) for consistency and Conversation Opener for engagement, using the Multi-Session Chat (MSC) dataset.\n- Table 2 (DMR task) shows MemGPT significantly outperforms fixed-context baselines across all models (GPT-3.5 Turbo, GPT-4, GPT-4 Turbo), with accuracy improvements from 38.7% to 66.9% and ROUGE-L scores from 0.394 to 0.827.\n- Table 3 (Conversation Opener task) demonstrates MemGPT’s ability to generate engaging openers, with GPT-4 + MemGPT achieving the highest SIM-1 (0.868) and SIM-3 (0.843) scores, and outperforming the human-created opener in SIM-1 and SIM-3, though slightly lower in SIM-H.\n- MemGPT maintains coherence by accessing full conversation history via paginated memory search, unlike baselines that rely on lossy summaries, leading to clear performance gains in consistency.\n- The conversation opener task evaluates engagement by comparing generated messages to gold personas and human-generated openers, showing MemGPT’s effectiveness in personalizing dialogue using long-range memory."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p6:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 6, "text": "- **Section 3.2** discusses challenges in document analysis due to limited context windows of transformer models (up to 128k tokens), noting that real-world documents (e.g., SEC Form 10-K) often exceed this, and that reasoning across multiple documents is difficult with fixed-context approaches.  \n- **Section 3.2.1** describes a multi-document QA evaluation where MemGPT is benchmarked against fixed-context baselines using the retriever-reader task from Liu et al. (2023a), with accuracy measured as the number of retrieved documents $K$ increases.  \n- The evaluation setup uses OpenAI’s `text-embedding-ada-002` for similarity search; MemGPT leverages PostgreSQL with `pgvector` and an HNSW index for fast archival storage retrieval, while fixed-context baselines fetch top-$K$ documents separately from LLM inference.  \n- **Figure 5** shows that MemGPT’s accuracy remains stable as context length increases, unlike truncation-based methods which degrade; it also performs equivalently with GPT-4 and GPT-4 Turbo.  \n- **Figure 6** illustrates MemGPT’s workflow: it queries archival storage (Wikipedia) via function calls to retrieve paginated results, which are then used to answer a question (e.g., “Who won the first Nobel Prize in physics?”).  \n- A separate section notes that MemGPT generates engaging openers (per Table 3) that are more verbose and comprehensive than human-written ones, highlighting the importance of storing information in working context."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "text": "- **Section 3.2.2 (Nested Key-Value Retrieval)** introduces a new synthetic task where an agent must retrieve values from a nested key-value structure (e.g., `831..ea5 → 5b8..4c3 → f37..617`), demonstrating MemGPT’s ability to collate information across multiple data sources.\n\n- **Figure 7** shows that MemGPT is the only approach capable of consistently completing the nested KV task beyond 2 nesting levels, outperforming baselines like GPT-3.5, GPT-4 Turbo, and GPT-4. Notably, MemGPT with GPT-4 performs better than MemGPT with GPT-4 Turbo.\n\n- **Figure 8** provides an example of MemGPT solving a nested KV task, illustrating how it iteratively queries archival storage to resolve the chain of keys until it finds a value that is not itself a key (e.g., `f37..617`).\n\n- The document QA task (results in Figure 5, not shown) highlights that fixed-context baselines are limited by the retriever’s ability to surface relevant documents within the context window, whereas MemGPT can scale beyond this limit by making multiple retriever calls.\n\n- MemGPT’s performance degrades with GPT-3.5 due to limited function calling capabilities but performs best with GPT-4. It often stops paging through retriever results before exhausting the database, even when theoretically capable of doing so."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p8:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 8, "text": "- **Nested KV Task Performance**: MemGPT outperforms GPT-3.5 and GPT-4 in nested key-value lookup tasks, maintaining accuracy across up to 4 nesting levels, while baseline models fail after 1–3 levels due to inability to perform multi-hop lookups.\n- **MemGPT’s Mechanism**: It achieves this by repeatedly querying key-value pairs stored in main memory via function calls, demonstrating its ability to combine multiple queries for complex lookups.\n- **Related Work (Section 4)**: The paper reviews prior work in long-context LLMs (e.g., sparse attention, neural memory), retrieval-augmented models (e.g., FLARE, interleaved retrieval with CoT), and LLMs as agents (e.g., memory-augmented planning, web browsing, multi-agent environments), positioning MemGPT as a novel OS-inspired memory system.\n- **Conclusion (Section 5)**: MemGPT is presented as an LLM system inspired by operating systems, using hierarchical memory and control flow to overcome context length limitations in document analysis and conversational agents.\n- **Key Contributions**: MemGPT enables processing of lengthy texts and long-term memory in dialogues by “paging” context in and out of memory, and the paper suggests future work in integrating databases, caches, and improved memory policies.\n- **Overall Impact**: The work argues that OS techniques like hierarchical memory management can unlock LLM potential within fixed context limits, representing a promising new direction for AI systems."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p9:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 9, "text": "This page (Page 9) is entirely composed of a **References** section, listing 23 academic papers and preprints related to large language models, transformers, retrieval-augmented generation, and long-context modeling.\n\nThe references cover a range of key topics, including:\n- **Long-context modeling** (e.g., Longformer, Transformer-XL, Reformer, Set Transformer, positional interpolation).\n- **Retrieval-augmented generation (RAG)** and dense passage retrieval for open-domain question answering (e.g., works by Karpukhin et al., Lewis et al., Izacard & Grave, Jiang et al.).\n- **Large language model pre-training and instruction tuning** (e.g., BERT, GPT-3, WebGPT, Ra-dit, AgentBench).\n- **Evaluation and analysis** of LLMs (e.g., ROUGE, \"Lost in the middle\" study on context usage).\n\nThe cited works are primarily from top conferences (ICML, NeurIPS) and arXiv preprints, spanning from 2018 to 2023, indicating a focus on recent advancements in the field.\n\nThere are no figures, tables, or main claims presented on this page—its purpose is solely to provide citations for prior work discussed in the paper."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p10:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 10, "text": "This page (Page 10) is entirely composed of a reference list for the paper \"MemGPT: Towards LLMs as Operating Systems\". It contains 15 citations to academic works, primarily from 2021–2023, with one from 1988. The references cover a range of topics relevant to large language models, including:\n\n- **LLM capabilities and reasoning**: Works on chain-of-thought prompting (Wei et al., 2022), reasoning and acting (Yao et al., 2022), and tool use (Schick et al., 2023).\n- **Memory and context**: Papers on long-term conversation (Xu et al., 2021), in-context retrieval (Ram et al., 2023), and memory-augmented models.\n- **Model architectures and efficiency**: References to attention mechanisms (Vaswani et al., 2017), linear attention (Wang et al., 2020), and input length extrapolation (Press et al., 2021).\n- **Model evaluation and benchmarks**: A citation to a paper on judging LLMs using mt-bench and chatbot arena (Zheng et al., 2023).\n- **Other relevant systems**: Includes foundational work on RAID (Patterson et al., 1988) and generative agents (Park et al., 2023).\n\nThe page does not contain any figures, tables, or original content—only a formatted list of references."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "text": "- **Section 6.1.1 (MEMGPT INSTRUCTIONS DMR)**: Provides example instructions for the MemGPT persona, emphasizing full role immersion without revealing AI identity, and using core memory and conversation search to answer user questions. Baseline models received a system prompt requiring them to answer based on a conversation summary, reply with 'NO ANSWER' if insufficient information exists, and avoid any additional text.\n\n- **Section 6.1.2 (LLM JUDGE DMR / OPENER)**: Describes an LLM judge used to evaluate answer correctness for the DMR task. The judge receives a question, a gold (ground truth) answer, and a generated answer, and must label the generated answer as 'CORRECT' or 'WRONG'. Grading is generous: any answer touching on the same topic as the gold answer is considered correct, even if verbose. Examples of correct and wrong answers are provided, along with strict formatting instructions for the judge’s output.\n\n- **Section 6.1.3 (SELF-INSTRUCT DMR DATASET GENERATION)**: Explains how DMR question/answer pairs were generated using a prompt and the original MSC dataset. The task is to write a \"memory challenge\" question from user A to user B, designed so that user B must have participated in the prior conversation (not just read the persona summary) to answer correctly. The prompt explicitly forbids creating questions that can be answered from persona summaries alone.\n\n- The page is part of the **Appendix (Section 6)** and focuses on **prompts and instructions** for MemGPT, baseline models, the LLM judge, and dataset generation.\n\n- All prompts are presented as text blocks, with no figures or tables. The content is technical and specific to the implementation and evaluation of the MemGPT system for dialogue memory retrieval (DMR)."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p12:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 12, "text": "- **Section 6.1.4** provides instructions for creating document analysis questions, emphasizing that questions must **only** be answerable from the chat log, not from persona information (to avoid \"cheating\").\n- A **good question example** asks about a Taco Bell near the beach mentioned in the chat log, which cannot be inferred from user A’s persona (“I like surfing”).\n- A **bad question example** asks if user A likes surfing, which is directly answerable from the persona, violating the instruction.\n- The page details two prompts: one for **MemGPT DOC-QA bot**, which must search archival memory and answer as if it’s 2018, and a **baseline prompt** that uses retrieved documents and requires citing the source text.\n- **Section 6.1.5** introduces an **LLM judge** to evaluate answer correctness and ensure answers are derived from provided text, not model weights, using a specific evaluation format."}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p13:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 13, "text": "- Page 13 of \"MemGPT: Towards LLMs as Operating Systems\" outlines evaluation criteria and task instructions for a key-value (K/V) retrieval task.\n- Evaluation rules state that an LLM response is \"CORRECT\" if it includes both the correct answer and supporting document text, even with minor wording differences; it is \"INCORRECT\" if it returns \"INSUFFICIENT INFORMATION\" or omits the \"DOCUMENT\" field.\n- Section 6.1.6 details the persona for the MemGPT agent: a DOC-QA bot instructed to persistently search archival memory and perform nested lookups until it verifies a value is not a key.\n- The baseline models are given a prompt to retrieve values from a JSON object with 128-bit UUID keys and values, performing nested lookups if a value is also a key.\n- The instructions emphasize iterative search and nested lookup behavior for both MemGPT and baselines, though MemGPT’s persona is more explicitly designed to encourage this behavior.\n- No figures or tables are present on this page."}
