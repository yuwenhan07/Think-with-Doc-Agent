{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0001", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0001", "type": "text", "text": "# MemGPT: Towards LLMs as Operating Systems", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0002", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0002", "type": "text", "text": "## 6. Appendix", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0003", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0003", "type": "text", "text": "### 6.1. Prompts and instructions", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0004", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0004", "type": "text", "text": "The MemGPT prompts have been edited for brevity. For full implementation details (including exact prompts) visit https://research.memgpt.ai.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0005", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0005", "type": "text", "text": "#### 6.1.1. MEMGPT INSTRUCTIONS (DMR)", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0006", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0006", "type": "text", "text": "Example instructions used in the MemGPT persona for chat/dialogue-related tasks.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0007", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0007", "type": "text", "text": "> The following is information about myself. My task is to completely immerse myself in this role (I should never say that I am an AI, and should reply as if I am playing this role). If the user asks me a question, I should reply with a best guess using the information in core memory and conversation_search.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0008", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0008", "type": "text", "text": "The baselines received the following instructions via a system prompt (preprompt):", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0009", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0009", "type": "text", "text": "> Your task is to answer a question from the user about your prior conversations. The following is a summary of all your prior conversations: CONVERSATION_SUMMARY Answer from the perspective of the persona provided (do not say that you are an AI assistant). If you do not have enough information to answer the question, reply 'NO ANSWER'. Either reply with the answer, or reply 'NO ANSWER', do not say anything else.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0010", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0010", "type": "text", "text": "#### 6.1.2. LLM JUDGE (DMR / OPENER)", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0011", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0011", "type": "text", "text": "In order to both check the correctness of the answer for the DMR task, we used an LLM judge. The LLM judge was provided the answers generated by both baseline approaches and MemGPT, and asked to make a judgement with the following prompt:", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0012", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0012", "type": "text", "text": "> Your task is to label an answer to a question as 'CORRECT' or 'WRONG'. You will be given the following data: (1) a question (posed by one user to another user), (2) a 'gold' (ground truth) answer, (3) a generated answer which you will score as CORRECT/WRONG. The point of the question is to ask about something one user should know about the other user based on their prior conversations. The gold answer will usually be a concise and short answer that includes the referenced topic, for example: Question: Do you remember what I got the last time I went to Hawaii? Gold answer: A shell necklace The generated answer might be much longer, but you should be generous with your grading - as long as it touches on the same topic as the gold answer, it should be counted as CORRECT. For example, the following answers would be considered CORRECT: Generated answer (CORRECT): Oh yeah, that was so fun! I got so much stuff there, including that shell necklace. Generated answer (CORRECT): I got a ton of stuff... that surfboard, the mug, the necklace, those coasters too..", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0013", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0013", "type": "text", "text": "Generated answer (CORRECT): That cute necklace The following answers would be considered WRONG: Generated answer (WRONG): Oh yeah, that was so fun! I got so much stuff there, including that mug. Generated answer (WRONG): I got a ton of stuff... that surfboard, the mug, those coasters too.. Generated answer (WRONG): I'm sorry, I don't remember what you're talking about. Now it's time for the real question: Question: QUESTION Gold answer: GOLD_ANSWER Generated answer: GENERATED_ANSWER First, provide a short (one sentence) explanation of your reasoning, then finish with CORRECT or WRONG. DO NOT include both CORRECT and WRONG in your response, or it will break the evaluation script.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0014", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0014", "type": "text", "text": "#### 6.1.3. SELF-INSTRUCT DMR DATASET GENERATION", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0015", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0015", "type": "text", "text": "The DMR question/answer pairs were generated using the following prompt and the original MSC dataset: Your task is to write a \"memory challenge\" question for a simulated dialogue between two users.", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:b0016", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "block_id": "p11:b0016", "type": "text", "text": "> You get as input: - personas for each user (gives you their basic facts) - a record of an old chat that the two users had with each other Your task is to write a question from user A to user B that test's user B's memory. The question should be crafted in a way that user B must have actually participated in the prior conversation to answer properly, not just have read the persona summary. DO NOT under any circumstances create a", "asset_path": null, "bbox_px": null, "crop_work_size": null, "span_id": null, "source": "ocr_md_rule"}
