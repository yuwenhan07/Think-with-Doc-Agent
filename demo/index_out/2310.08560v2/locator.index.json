{
  "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0",
  "figures": {},
  "tables": {},
  "sections": {},
  "page_headings": {
    "5": [
      "| GPT-4             | 32.1%      | 0.296         |"
    ],
    "11": [
      "#### 6.1.1. MEMGPT INSTRUCTIONS (DMR)"
    ],
    "12": [
      "## 6.1.4. DOCUMENT ANALYSIS INSTRUCTIONS"
    ],
    "13": [
      "## 6.1.6. K/V TASK INSTRUCTIONS",
      "Baselines were instructed with the following prompt:"
    ]
  },
  "pages": {
    "1": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0001.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems **Charles Packer**Â¹ **Sarah Wooders**Â¹ **Kevin Lin**Â¹ **Vivian Fang**Â¹ **Shishir G. Patil**Â¹ **Ion Stoica**Â¹ **Joseph E. Gonzalez**Â¹ --- ## Abstract Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose *virtual context management*, a technique drawing inspi"
    },
    "2": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0002.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Figure 1 **February 7** > **User:** How was your day today? > **MemGPT:** fun my bf james baked me a birthday cake > **User:** Oh wow, happy birthday! ðŸŽ‰ > **System Alert: Memory Pressure** > `working_context.append(\"Birthday is February 7\")` > `working_context.append(\"Boyfriend named James\")` *Figure 1. MemGPT (left) writes data to persistent memory after it receives a system alert about limited context space.* ## Figure 2 **February 7** > **User:**"
    },
    "3": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0003.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Figure 3: MemGPT Architecture ```plaintext LLM Finite Context Window (e.g. 8k tokens) -------------------------------------------- | Prompt Tokens | Completion Tokens |----------------------------------------|------------------- | [System Instructions] (Read-Only) | [Output Buffer] | (MemGPT System Prompt) | (Read-Write) | | | [Working Context] (Read-Write) | | (Write via Functions) | | | | [FIFO Queue] (Read-Write) | | (Write via Queue Manager) | |"
    },
    "4": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0004.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Table 1. Comparing context lengths of commonly used models and LLM APIs (data collected 1/2024) *Approximate message count assuming a preprompt of 1k tokens, and an average message size of ~50 tokens (~250 characters). 'Open' means the model is open-source or open-weights (vs only available behind an API).* | Model / API name | Open? | Context Window Tokens | *Messages | |---------------------------|-------|------------------------|-----------| | Ll"
    },
    "5": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0005.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Table 2. Deep memory retrieval (DMR) performance. In this task, the agent is asked a specific question about a topic discussed in a prior conversation (sessions 1â€“5). The agentâ€™s response is scored against the gold answer. MemGPT significantly outperforms the fixed-context baselines. | Model | Accuracy â†‘ | ROUGE-L (R) â†‘ | |-------------------|------------|---------------| | GPT-3.5 Turbo | 38.7% | 0.394 | | + MemGPT | 66.9% | 0.629 | | GPT-4 | 32.1%"
    },
    "6": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0006.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Figure 5. Document QA task performance MemGPT's performance is unaffected by increased context length. Methods such as truncation can extend the effective context lengths of fixed-length models such as GPT-4, but such compression methods will lead to performance degradation as the necessary compression grows. Running MemGPT with GPT-4 and GPT-4 Turbo have equivalent results on this task. ![Figure 5: Document QA task performance](https://i.imgur.com/"
    },
    "7": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0007.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## Figure 7. Nested KV retrieval task performance. MemGPT is the only approach that is able to consistently complete the nested KV task beyond 2 nesting levels. While GPT-4 Turbo performs better as a baseline, MemGPT with GPT-4 Turbo performs worse than MemGPT with GPT-4. --- ## Figure 8. An example of MemGPT (left) solving the nested KV task (UUIDs shortened for readability). In this particular example, the key-value pair has two nesting levels: `831."
    },
    "8": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0008.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems where values themselves may be keys, thus requiring the agent to perform a multi-hop lookup. In our setup, we fix the total number of UUIDs pairs to 140, corresponding to roughly 8k tokens (the context length of our GPT-4 baseline). We vary the total number of nesting levels from 0 (the initial key-value pairâ€™s value is not a key) to 4 (ie 4 total KV lookups are required to find the final value), and sample 30 different ordering configurations includin"
    },
    "9": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0009.png",
      "text_snippet": "# References Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. *arXiv preprint arXiv:2004.05150*, 2020. Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In *International conference on machine learning*, pp. 2206â€“2240. PMLR, 2022. Tom Brown, Benjamin Mann, Ni"
    },
    "10": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0010.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## References - **feedback.** *Advances in Neural Information Processing Systems*, 35:27730â€“27744, 2022. - **Joon Sung Park, Joseph C Oâ€™Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein.** Generative agents: Interactive simulacra of human behavior. *arXiv preprint arXiv:2304.03442*, 2023. - **David A Patterson, Garth Gibson, and Randy H Katz.** A case for redundant arrays of inexpensive disks (raid). In *Proceedings of t"
    },
    "11": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0011.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## 6. Appendix ### 6.1. Prompts and instructions The MemGPT prompts have been edited for brevity. For full implementation details (including exact prompts) visit https://research.memgpt.ai. #### 6.1.1. MEMGPT INSTRUCTIONS (DMR) Example instructions used in the MemGPT persona for chat/dialogue-related tasks. > The following is information about myself. My task is to completely immerse myself in this role (I should never say that I am an AI, and should r"
    },
    "12": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0012.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems ## 6.1.4. DOCUMENT ANALYSIS INSTRUCTIONS Example instructions used in the preprompt for document analysis tasks. --- ### Instructions for Creating Questions - **Avoid** questions that can be answered using persona information (considered cheating). - **Instead**, write a question that can **only** be answered by looking at the old chat log (and is **not** contained in the persona information). #### Example: **Old chat between user A and user B:** > A: "
    },
    "13": {
      "image_path": "/home/work/workspace/Think-with-Doc-Agent/demo/imgs/2310.08560v2/page_0013.png",
      "text_snippet": "# MemGPT: Towards LLMs as Operating Systems answers]\". The questions is provided in the format \"QUESTION: [question]\". If the LLM response contains both the correct answer and corresponding document text, the response is correct. Even if the LLM's answer and the true answer are slightly different in wording, the response is still correct. For example, if the answer is more specific than the true answer or uses a different phrasing that is still correct, the response is correct. If the LLM respon"
    }
  }
}