{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p1:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 1, "text": "MemGPT introduces virtual context management, inspired by OS memory paging, to extend LLM context beyond fixed limits. It intelligently manages storage tiers to enable long document analysis and multi-session chat. The system uses function calls to page data between context window and external storage, mimicking hierarchical memory. It addresses the quadratic cost of extending context and poor utilization in long-context models. MemGPT treats context as constrained memory and is evaluated on document analysis and conversational agents. Code and data are released at https://research.memgpt.ai.", "section_type": "abstract", "page_section": "Abstract", "section_relevance": 1.3, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0001.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p2:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 2, "text": "MemGPT introduces an OS-inspired memory architecture for LLMs, using main context (in-context prompt tokens) and external context (out-of-context data) to simulate virtual memory. It manages context via system instructions, working context, and a FIFO queue, enabling LLMs to handle unbounded context. Figures 1 and 2 illustrate how MemGPT writes to persistent memory and retrieves historical data. The Queue Manager handles message flow between recall storage and the FIFO queue to support long conversations and document analysis.", "section_type": "methodology", "page_section": "2. MemGPT (MemoryGPT)", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0002.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p3:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 3, "text": "- Figure 3 illustrates MemGPT‚Äôs architecture, augmenting a fixed-context LLM with a hierarchical memory system (archival, recall, FIFO queue) and function-based data movement.\n- The Queue Manager controls context overflow via warnings and flushing, moving data to archival/recall storage when token limits (e.g., 70% or 100% of window) are exceeded.\n- Section 2.3 details the Function Executor, which parses LLM outputs as function calls to autonomously manage memory, enabling self-directed editing and retrieval.\n- MemGPT uses system instructions to guide the LLM on memory interactions, including function schemas and memory hierarchy descriptions, and implements pagination to avoid context overflow.\n- A feedback loop returns execution results and errors to the LLM, enabling adaptive behavior and learning from memory management decisions.", "section_type": "methodology", "page_section": "2.3. Function executor (handling of completion tokens)", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0003.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p4:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 4, "text": "- Table 1 compares context window sizes and message capacities of various LLMs and APIs as of Jan 2024, highlighting open vs. closed models.\n- Section 2.4 explains MemGPT‚Äôs event-driven control flow and function chaining, enabling sequential function calls and context updates without user intervention.\n- Section 3 introduces experiments in conversational agents and document analysis, using expanded datasets and proposing a new nested KV retrieval task for multi-hop reasoning.\n- Implementation details clarify model endpoints used (e.g., GPT-4 Turbo = gpt-4-1106-preview) and state that all baseline models are tested to isolate MemGPT‚Äôs contribution.\n- Section 3.1 outlines criteria for conversational agents: consistency (coherent long-term memory) and engagement (personalization via user history).\n- Figure 4 illustrates MemGPT updating working memory during a conversation, showing dynamic context modification via code-like commands.", "section_type": "methodology", "page_section": "2.4. Control flow and function chaining", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0004.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p5:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 5, "text": "- Page 5 presents MemGPT‚Äôs evaluation on two tasks: Deep Memory Retrieval (DMR) for consistency and Conversation Opener for engagement, using the Multi-Session Chat (MSC) dataset.\n- Table 2 shows MemGPT significantly outperforms fixed-context baselines (e.g., GPT-4 Turbo + MemGPT achieves 93.4% accuracy vs. 35.3% without), proving memory improves recall and coherence.\n- Table 3 shows MemGPT‚Äôs conversation openers exceed human-created openers in similarity metrics (SIM-1, SIM-3, SIM-H) across multiple LLMs, indicating superior engagement.\n- The DMR task tests if agents can answer questions requiring past context; the opener task evaluates if agents can personalize messages using accumulated persona knowledge.\n- MemGPT accesses full conversation history via paginated search, while baselines use lossy summaries, explaining MemGPT‚Äôs superior performance in both tasks.", "section_type": "results", "page_section": "3.1.1. DEEP MEMORY RETRIEVAL TASK (CONSISTENCY) and 3.1.2. CONVERSATION OPENER TASK (ENGAGEMENT)", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0005.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p6:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 6, "text": "- Figure 5 shows MemGPT maintains stable QA accuracy as context length increases, unlike fixed-context models like GPT-4 which degrade.\n- MemGPT uses memory to generate more verbose, comprehensive, and engaging openers compared to human baselines (Table 3).\n- Section 3.2 introduces document analysis challenges due to LLMs' limited context windows, citing examples like 10-K reports exceeding 1M tokens.\n- Section 3.2.1 details the multi-document QA evaluation using NaturalQuestions-Open, where MemGPT uses archival storage with vector search (pgvector) to retrieve documents dynamically.\n- Figure 6 illustrates MemGPT solving a QA task by querying archival storage via function calls to retrieve paginated Wikipedia results.", "section_type": "methodology", "page_section": "3.2. MemGPT for document analysis", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0006.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p7:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 7, "text": "- Page 7 presents results for MemGPT on document QA and introduces the nested KV retrieval task.\n- Figure 7 shows MemGPT is the only method to consistently succeed beyond 2 nesting levels in nested KV retrieval, though performance varies by base LLM.\n- Figure 8 illustrates how MemGPT resolves nested key-value chains by iterative archival storage queries until a non-key value is found.\n- MemGPT overcomes fixed-context LLM limitations by paginating through retriever results, unlike baselines capped by context window size.\n- The nested KV task, based on synthetic UUID pairs, tests MemGPT‚Äôs ability to collate information across multiple data sources via recursive lookups.", "section_type": "results", "page_section": "3.2.2. NESTED KEY-VALUE RETRIEVAL (KV)", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0007.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p8:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 8, "text": "MemGPT excels at nested key-value lookup tasks where baseline LLMs like GPT-3.5 and GPT-4 fail, demonstrating its ability to perform multi-hop reasoning via function queries. The paper situates MemGPT within related work on long-context LLMs, retrieval-augmented models, and LLM agents, highlighting its OS-inspired memory hierarchy. The conclusion emphasizes MemGPT‚Äôs success in overcoming context length limits for document analysis and conversational agents, suggesting future work on integrating databases, caches, and improved memory policies.", "section_type": "conclusion", "page_section": "5. Conclusion", "section_relevance": 1.2, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0008.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p9:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 9, "text": "This page contains the 'References' section of the paper 'MemGPT: Towards LLMs as Operating Systems', listing academic citations for related work on transformers, long-context modeling, retrieval-augmented generation, and evaluation methods. It includes papers from venues like ICML, NeurIPS, and arXiv preprints from 2018 to 2023.", "section_type": "other", "page_section": "References", "section_relevance": 1.0, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0009.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p10:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 10, "text": "This page is a reference list containing 16 academic papers and preprints from 2017 to 2023, covering topics such as generative agents, RAID systems, attention mechanisms, retrieval-augmented LMs, tool use in LLMs, Llama 2, chain-of-thought reasoning, and long-term conversation models.", "section_type": "other", "page_section": "unknown", "section_relevance": 1.0, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0010.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p11:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 11, "text": "- Page 11 details prompts and instructions for MemGPT's DMR task, including persona immersion rules and baseline preprompts.\n- It describes the LLM judge protocol for evaluating answer correctness, with examples of CORRECT/WRONG judgments based on topic alignment with gold answers.\n- It outlines the self-instruct method for generating DMR dataset questions using MSC data, requiring memory-based questions from simulated dialogues.", "section_type": "methodology", "page_section": "6.1. Prompts and instructions", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0011.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p12:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 12, "text": "- Page 12 details instructions for document analysis tasks in MemGPT, emphasizing that questions must require retrieval from chat logs, not persona data.\n- It provides examples of good (context-dependent) vs. bad (persona-inferable) questions.\n- Specifies prompt formats for MemGPT and baseline models to answer using archival memory, requiring explicit citation of source text.\n- Introduces an LLM judge to evaluate answer correctness and source fidelity, ensuring answers derive from provided documents, not model weights.", "section_type": "methodology", "page_section": "6.1.4. DOCUMENT ANALYSIS INSTRUCTIONS", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0012.png"}
{"id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0:p13:summary", "doc_id": "sha256:9f674bcff69c86f11c813dcfad613d8841f5f8ed17979e3c4df06a91df7762e0", "page_number": 13, "text": "- Defines correctness criteria for LLM responses: must include correct answer and document text; phrasing flexibility allowed; 'INSUFFICIENT INFORMATION' or missing 'DOCUMENT' field = incorrect.\n- Section 6.1.6 details K/V task instructions for the MemGPT agent, which is prompted to iteratively search archival memory until verifying a value is not a key.\n- Baselines are given a prompt to perform nested lookups in a JSON object of UUID key-value pairs, returning the final non-key value.", "section_type": "methodology", "page_section": "6.1.6. K/V TASK INSTRUCTIONS", "section_relevance": 1.1, "page_image_path": "/Users/yuwenhan/Library/Mobile Documents/com~apple~CloudDocs/Documents/üêü/ÁßëÁ†î/Learn.agent/DocAgent/demo/imgs/2310.08560v2/page_0013.png"}
